{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至mqgao@kaikeba.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.7.6日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:   \n",
    "- 个性化推荐引擎  \n",
    "- 金融风控系统\n",
    "- 智慧医疗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:   \n",
    "- 一方面可以通过Github去star或者fork比较好的项目，向其他的优秀开发者学习；另一方面通过与git的配合可以很好的管理自己的项目代码\n",
    "- jupyter从功能上来说可以做笔记、写代码、运行代码、查看结果，并在其中可视化数据；从交互上来说，允许把代码写入独立的cell中，然后单独执行，方便初学者测试特定的代码，并及时看到反馈\n",
    "- pycharm是一款Python 编辑器，可以与jupyter配合使用。当代码量比较小/需要可视化时使用jupyter比较友好；当代码量比较大时使用pycharm比较好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- 个人理解，概率模型就是从过往的相关数据中，提炼出一套为了解决某个问题或做出某个决策的数学模型。\n",
    "- 概率模型的的可靠程度与数据源的可靠程度存在强正相关性，数据源越可靠真实，那么提炼出的概率模型在处理问题时的正确程度就会越高\n",
    "- 概率模型的的可靠程度与数据源数量存在强正相关性，数据源越越多，那么提炼出的概率模型在处理问题时的正确程度就会越高\n",
    "- 概率模型需要能够不断进行调整优化，因为概率模型来源于数据，而数据又是有时效性的，所以需要不断的增加新的数据或淘汰旧的数据来调整概率模型的适应性\n",
    "- 概率模型不追求完全肯定的结果，更加关注不同情况出现的概率，通过将概率之间的比较，来得出一个相对正确的结论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- 根据某个人三代之内家属的患病情况来推断本人得某种疾病的概率\n",
    "- 支付过程中判断当前操作人员是否为本人\n",
    "- 预测机票价格的上涨情况\n",
    "- 预测某款新产品的销售情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- Why do we use probability ?\n",
    "  - 想要通过以往的数据来推断某个情况是否确定出现是十分困难的，不仅计算量巨大，而且数据源的质量也会直接影响最终的判断结果,这样得出的结果反而会不是那么的精确。而通过概率计算则不同，处理过程相对简单，我们不再追求一个确定的结果，转而寻求一种可能性，可能性越高，代表情况出现的概率越大。\n",
    "- what's the difficult points for programming based on parsing and pattern match?\n",
    "  - 一种场景可能存在多种处理方式，而且这些处理方式很有可能也无法迁移到下一种场景中去使用，即我们无法提炼出一套通用的规则来处理多种不同的场景，只能说去不断的提升规则的通用性。就拿语言翻译来说，同一种语言可能就会存在很多种翻译方式，不同人的翻译方式可能也不同，而这些翻译方式在换一种语言之后也会完全不适用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "通过某种规则来推导任意一个句子出现的概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- 智能客服\n",
    "- 智能音箱\n",
    "- 聊天机器人\n",
    "- 句子/文章生成器\n",
    "- 翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "是一种上下文无关模型。该模型仅仅考虑当前词本身出现的概率，而不考虑当前词的上下文环境。即一个句子出现的概率等于句子中每个单词概率乘积。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- disadvantages\n",
    "  - 计算结果误差较大，没有考虑一个句子中不同位置的单词的相互影响，即把条件概率简化成了独立事件\n",
    "- advantages\n",
    "  - 计算简单方便，在计算一个单词在数据源中出现的概率或生成的较短句子的合理性时适用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  \n",
    "当前词出现的概率只与它前面的一个词有关系，是一种较为简单的上下文有关模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = null\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第一个语法：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习生介绍\n",
    "player = \"\"\"\n",
    "player = 寒暄 序号 介绍 专业技能 客套 结尾 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称\n",
    "人称 = 评委老师们 | 现场粉丝们 | 电视机前的观众们\n",
    "打招呼 = 大家早上好， | 大家晚上好，\n",
    "序号 = 我是 数字 号练习生 ，\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "介绍 = 我是 姓名 | 我是 姓名 亲戚 姓名1\n",
    "姓名 = 张三 | 李四 | 王五 |老六\n",
    "亲戚 = 的弟弟 | 的妹妹 | 的哥哥 | 的姐姐\n",
    "姓名1 = 大锤 | 狗剩 | 铁柱 | 鸭蛋\n",
    "专业技能 = 我会 技能+ ，\n",
    "技能+ = 技能 | 技能 技能+\n",
    "技能 = 唱 | 跳 | rap | 篮球\n",
    "客套 = 谦虚词 大家给我 行动 ，\n",
    "谦虚词 = 请 | 感谢 | 希望\n",
    "行动 = 投票 | 鼓掌 | 支持\n",
    "结尾 = 音乐响起来！\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    \"\"\"生成对应语法字典结构\"\"\"\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split): # 使用split进行分割，返回分割后的字符串列表。把每一行进行分割\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split) # 把每一行中左右两边进行分割\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')] # 把每一行进行分割操作后的内容赋值给grammar字典\n",
    "    return grammar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_grammar_player = create_grammar(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player': [['寒暄', '序号', '介绍', '专业技能', '客套', '结尾']],\n",
       " '寒暄': [['称谓', '打招呼'], ['打招呼']],\n",
       " '称谓': [['人称']],\n",
       " '人称': [['评委老师们'], ['现场粉丝们'], ['电视机前的观众们']],\n",
       " '打招呼': [['大家早上好，'], ['大家晚上好，']],\n",
       " '序号': [['我是', '数字', '号练习生', '，']],\n",
       " '数字': [['单个数字'], ['数字', '单个数字']],\n",
       " '单个数字': [['1'], ['2'], ['3'], ['4'], ['5'], ['6'], ['7'], ['8'], ['9']],\n",
       " '介绍': [['我是', '姓名'], ['我是', '姓名', '亲戚', '姓名1']],\n",
       " '姓名': [['张三'], ['李四'], ['王五'], ['老六']],\n",
       " '亲戚': [['的弟弟'], ['的妹妹'], ['的哥哥'], ['的姐姐']],\n",
       " '姓名1': [['大锤'], ['狗剩'], ['铁柱'], ['鸭蛋']],\n",
       " '专业技能': [['我会', '技能+', '，']],\n",
       " '技能+': [['技能'], ['技能', '技能+']],\n",
       " '技能': [['唱'], ['跳'], ['rap'], ['篮球']],\n",
       " '客套': [['谦虚词', '大家给我', '行动', '，']],\n",
       " '谦虚词': [['请'], ['感谢'], ['希望']],\n",
       " '行动': [['投票'], ['鼓掌'], ['支持']],\n",
       " '结尾': [['音乐响起来！']]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_grammar_player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**第二个语法：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演唱会歌手介绍\n",
    "singer = \"\"\"\n",
    "singer = 寒暄 介绍 唱歌 结尾\n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称\n",
    "人称 = 这边的朋友 | 那边的朋友 | 后边的朋友 | 看台的朋友\n",
    "打招呼 = 大家早上好， | 大家晚上好，\n",
    "介绍 = 我是 姓名 ， | 我是 姓名 演唱会名称 演唱会 的 嘉宾 嘉宾名 ，\n",
    "姓名 = 周杰伦 | 林俊杰 | 好妹妹 | 苏打绿\n",
    "演唱会名称 = 地表最强 | 圣所 | 自在如风 | 无与伦比的美丽\n",
    "嘉宾名 = 蔡依林 | 李荣浩 | 方大同 | 张悬\n",
    "唱歌 = 接下来我要唱的歌曲是 歌名 ，\n",
    "歌名 = 双截棍 | 一千年以后  | 你曾是少年 | 他夏了夏天\n",
    "结尾 = Music！\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_grammar_singer = create_grammar(singer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'singer': [['寒暄', '介绍', '唱歌', '结尾']],\n",
       " '寒暄': [['称谓', '打招呼'], ['打招呼']],\n",
       " '称谓': [['人称']],\n",
       " '人称': [['这边的朋友'], ['那边的朋友'], ['后边的朋友'], ['看台的朋友']],\n",
       " '打招呼': [['大家早上好，'], ['大家晚上好，']],\n",
       " '介绍': [['我是', '姓名', '，'],\n",
       "  ['我是', '姓名', '演唱会名称', '演唱会', '的', '嘉宾', '嘉宾名', '，']],\n",
       " '姓名': [['周杰伦'], ['林俊杰'], ['好妹妹'], ['苏打绿']],\n",
       " '演唱会名称': [['地表最强'], ['圣所'], ['自在如风'], ['无与伦比的美丽']],\n",
       " '嘉宾名': [['蔡依林'], ['李荣浩'], ['方大同'], ['张悬']],\n",
       " '唱歌': [['接下来我要唱的歌曲是', '歌名', '，']],\n",
       " '歌名': [['双截棍'], ['一千年以后'], ['你曾是少年'], ['他夏了夏天']],\n",
       " '结尾': [['Music！']]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_grammar_singer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "choice = random.choice\n",
    "\n",
    "def generate(gram, target):\n",
    "    \n",
    "    if target not in gram: \n",
    "        return target \n",
    "    \n",
    "    expaned = [generate(gram, t) for t in choice(gram[target])]  \n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expaned if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'评委老师们大家早上好，我是71号练习生，我是王五的妹妹铁柱我会篮球，请大家给我鼓掌，音乐响起来！'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram=example_grammar_player, target='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大家晚上好，我是好妹妹，接下来我要唱的歌曲是你曾是少年，Music！'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram=example_grammar_singer, target='singer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(n, example = example_grammar_player , name='player'):\n",
    "    for i in range(n):\n",
    "        print(generate(gram=example, target=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大家早上好，我是698385号练习生，我是老六的妹妹大锤我会rap唱，感谢大家给我支持，音乐响起来！\n",
      "大家晚上好，我是464号练习生，我是老六我会篮球，希望大家给我支持，音乐响起来！\n",
      "电视机前的观众们大家晚上好，我是36号练习生，我是老六的姐姐鸭蛋我会跳，感谢大家给我支持，音乐响起来！\n",
      "评委老师们大家晚上好，我是5号练习生，我是张三我会篮球，希望大家给我支持，音乐响起来！\n",
      "大家早上好，我是63644号练习生，我是老六的弟弟大锤我会跳rap唱跳篮球，希望大家给我鼓掌，音乐响起来！\n",
      "大家早上好，我是3888号练习生，我是张三我会篮球，希望大家给我投票，音乐响起来！\n",
      "电视机前的观众们大家早上好，我是57571号练习生，我是李四我会篮球，感谢大家给我鼓掌，音乐响起来！\n",
      "大家晚上好，我是9号练习生，我是李四的妹妹狗剩我会唱，请大家给我投票，音乐响起来！\n",
      "电视机前的观众们大家晚上好，我是334号练习生，我是张三我会篮球唱跳，希望大家给我投票，音乐响起来！\n",
      "现场粉丝们大家早上好，我是87号练习生，我是李四的妹妹大锤我会跳跳，请大家给我支持，音乐响起来！\n"
     ]
    }
   ],
   "source": [
    "generate_n(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获得文本数据集中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def data(addr):\n",
    "    filename = addr\n",
    "    comment = pd.read_csv(filename)\n",
    "    articles = comment['comment'].tolist()\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comment = data('movie_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1星半吧，这个结尾实在让人吐槽无能……'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_comment[20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 清洗数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def token(string):\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comment_clean = [''.join(token(str(a)))for a in data_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_comment_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1星半吧这个结尾实在让人吐槽无能'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_comment_clean[20000] # 检验清洗结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 切词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_comment_clean.txt', 'w',encoding='utf-8') as f:\n",
    "    for a in data_comment_clean:\n",
    "        f.write(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = []\n",
    "for line in open('data_comment_clean.txt',encoding='utf-8'):\n",
    "      TOKEN += cut(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "words_count = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 328253),\n",
       " ('了', 102408),\n",
       " ('是', 73433),\n",
       " ('我', 50520),\n",
       " ('都', 36251),\n",
       " ('很', 34760),\n",
       " ('看', 33850),\n",
       " ('电影', 33638),\n",
       " ('也', 32064),\n",
       " ('和', 31291),\n",
       " ('在', 31234),\n",
       " ('不', 28473),\n",
       " ('有', 27930),\n",
       " ('就', 25690),\n",
       " ('人', 23818),\n",
       " ('好', 22562),\n",
       " ('啊', 20783),\n",
       " ('这', 17878),\n",
       " ('一个', 17343),\n",
       " ('还', 17318),\n",
       " ('你', 17293),\n",
       " ('还是', 16425),\n",
       " ('但', 15578),\n",
       " ('故事', 15007),\n",
       " ('没有', 14343),\n",
       " ('就是', 14005),\n",
       " ('喜欢', 13566),\n",
       " ('让', 13298),\n",
       " ('太', 12619),\n",
       " ('又', 11569),\n",
       " ('剧情', 11350),\n",
       " ('没', 10901),\n",
       " ('说', 10761),\n",
       " ('吧', 10744),\n",
       " ('他', 10672),\n",
       " ('得', 10491),\n",
       " ('不错', 10416),\n",
       " ('到', 10356),\n",
       " ('给', 10303),\n",
       " ('上', 10100),\n",
       " ('这个', 10058),\n",
       " ('被', 9941),\n",
       " ('对', 9808),\n",
       " ('最后', 9694),\n",
       " ('一部', 9693),\n",
       " ('片子', 9583),\n",
       " ('什么', 9572),\n",
       " ('能', 9531),\n",
       " ('与', 9173),\n",
       " ('可以', 8972),\n",
       " ('多', 8951),\n",
       " ('不是', 8810),\n",
       " ('最', 8677),\n",
       " ('觉得', 8626),\n",
       " ('中', 8419),\n",
       " ('导演', 8390),\n",
       " ('自己', 8354),\n",
       " ('拍', 8198),\n",
       " ('要', 8098),\n",
       " ('好看', 8059),\n",
       " ('真的', 7904),\n",
       " ('感觉', 7826),\n",
       " ('但是', 7723),\n",
       " ('里', 7658),\n",
       " ('那', 7508),\n",
       " ('有点', 7478),\n",
       " ('想', 7451),\n",
       " ('这部', 7433),\n",
       " ('会', 7422),\n",
       " ('去', 7290),\n",
       " ('把', 7150),\n",
       " ('着', 7083),\n",
       " ('这么', 6784),\n",
       " ('小', 6613),\n",
       " ('个', 6570),\n",
       " ('而', 6521),\n",
       " ('这样', 6471),\n",
       " ('真是', 6449),\n",
       " ('那么', 6431),\n",
       " ('这种', 6377),\n",
       " ('不过', 6293),\n",
       " ('时候', 6217),\n",
       " ('挺', 6216),\n",
       " ('片', 6201),\n",
       " ('更', 6146),\n",
       " ('比', 6089),\n",
       " ('却', 5990),\n",
       " ('爱', 5881),\n",
       " ('我们', 5875),\n",
       " ('大', 5742),\n",
       " ('像', 5699),\n",
       " ('虽然', 5633),\n",
       " ('演技', 5631),\n",
       " ('其实', 5572),\n",
       " ('看到', 5450),\n",
       " ('知道', 5385),\n",
       " ('再', 5351),\n",
       " ('演员', 5321),\n",
       " ('那个', 5123),\n",
       " ('才', 5063)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    if word in words_count: return words_count[word] / len(TOKEN)\n",
    "    else:\n",
    "        return 1 / len(TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-gram语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2 : return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 判断文本合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probablity(sentence):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]): \n",
    "        next_ = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_)/prob_1(word)\n",
    "        \n",
    "        sentence_pro *= probability\n",
    "    \n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n_p(n, example = example_grammar_player , name='player'):\n",
    "    for i in range(n):\n",
    "        se = generate(gram=example, target=name)\n",
    "        pro = get_probablity(se)\n",
    "        print(f'句子:{se} 合理程度:{pro}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子:现场粉丝们大家晚上好，我是88号练习生，我是李四我会篮球，感谢大家给我投票，音乐响起来！ 合理程度:8.167320998308667e-58\n",
      "句子:评委老师们大家早上好，我是89号练习生，我是李四的弟弟大锤我会跳，感谢大家给我鼓掌，音乐响起来！ 合理程度:4.543225238942941e-62\n",
      "句子:大家晚上好，我是8678号练习生，我是王五我会唱唱唱篮球，请大家给我鼓掌，音乐响起来！ 合理程度:4.017258314627102e-53\n",
      "句子:现场粉丝们大家早上好，我是6号练习生，我是李四我会篮球篮球唱跳，感谢大家给我鼓掌，音乐响起来！ 合理程度:6.31250081224785e-61\n",
      "句子:现场粉丝们大家晚上好，我是8号练习生，我是李四的弟弟大锤我会rap跳，希望大家给我鼓掌，音乐响起来！ 合理程度:1.0618388001317356e-66\n",
      "句子:评委老师们大家早上好，我是9号练习生，我是老六的妹妹鸭蛋我会跳篮球跳rap，请大家给我投票，音乐响起来！ 合理程度:3.884357916383903e-67\n",
      "句子:电视机前的观众们大家早上好，我是9号练习生，我是王五我会跳，请大家给我支持，音乐响起来！ 合理程度:2.4024073662146496e-54\n",
      "句子:大家晚上好，我是1号练习生，我是张三的姐姐铁柱我会唱，请大家给我投票，音乐响起来！ 合理程度:9.97604981267799e-60\n",
      "句子:评委老师们大家早上好，我是3号练习生，我是张三我会篮球rap跳，感谢大家给我支持，音乐响起来！ 合理程度:2.9547852267760888e-61\n",
      "句子:现场粉丝们大家晚上好，我是5157号练习生，我是李四我会篮球跳，请大家给我鼓掌，音乐响起来！ 合理程度:3.664905711834916e-59\n"
     ]
    }
   ],
   "source": [
    "generate_n_p(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(n, example = example_grammar_player , name='player'): \n",
    "    t = []\n",
    "    for i in range(n):\n",
    "        s = []\n",
    "        se = generate(gram=example, target=name)\n",
    "        s.append(se)\n",
    "        pro = get_probablity(se)\n",
    "        s.append(pro)\n",
    "        t.append(s)\n",
    "        print(f'句子:{se} 合理程度:{pro}')\n",
    "    best_sentence = sorted(t, key=lambda x: x[1], reverse=True)[0]\n",
    "    print(f'\\n共生成{n}个句子，其中最合理的句子及其合理程度为：{best_sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "句子:大家早上好，我是2912号练习生，我是王五的妹妹大锤我会rap跳跳唱跳，请大家给我支持，音乐响起来！ 合理程度:6.359328857064652e-58\n",
      "句子:评委老师们大家早上好，我是2号练习生，我是老六的哥哥大锤我会rap，请大家给我支持，音乐响起来！ 合理程度:1.8616601229385235e-62\n",
      "句子:大家早上好，我是2号练习生，我是李四我会rap，感谢大家给我投票，音乐响起来！ 合理程度:1.9281031082513514e-44\n",
      "句子:大家早上好，我是755号练习生，我是李四我会篮球，希望大家给我鼓掌，音乐响起来！ 合理程度:2.32689960997987e-44\n",
      "句子:电视机前的观众们大家晚上好，我是962号练习生，我是王五的妹妹鸭蛋我会篮球raprap，感谢大家给我支持，音乐响起来！ 合理程度:1.3605176912446493e-64\n",
      "句子:现场粉丝们大家早上好，我是1号练习生，我是李四的哥哥大锤我会篮球跳，请大家给我鼓掌，音乐响起来！ 合理程度:1.1211414251960253e-62\n",
      "句子:现场粉丝们大家晚上好，我是2号练习生，我是张三我会唱，感谢大家给我鼓掌，音乐响起来！ 合理程度:4.430416526824808e-63\n",
      "句子:大家晚上好，我是44号练习生，我是李四的哥哥狗剩我会rap跳唱唱rap唱，希望大家给我投票，音乐响起来！ 合理程度:5.889121298768288e-68\n",
      "句子:大家晚上好，我是714号练习生，我是王五的弟弟铁柱我会跳，感谢大家给我投票，音乐响起来！ 合理程度:2.1897919050968836e-56\n",
      "句子:大家晚上好，我是8号练习生，我是老六我会唱跳rap跳篮球，请大家给我投票，音乐响起来！ 合理程度:2.322198499296698e-61\n",
      "句子:大家晚上好，我是47号练习生，我是张三我会跳跳跳rap，希望大家给我投票，音乐响起来！ 合理程度:2.0591739544591335e-57\n",
      "句子:大家晚上好，我是5号练习生，我是李四的弟弟大锤我会rap，请大家给我支持，音乐响起来！ 合理程度:8.804690753044206e-58\n",
      "句子:大家早上好，我是368871号练习生，我是王五我会rap篮球跳，感谢大家给我支持，音乐响起来！ 合理程度:1.1015098799347495e-48\n",
      "句子:评委老师们大家早上好，我是866号练习生，我是李四的弟弟鸭蛋我会rap，请大家给我投票，音乐响起来！ 合理程度:2.1699442268228385e-56\n",
      "句子:现场粉丝们大家晚上好，我是9号练习生，我是老六我会唱rap篮球rap，感谢大家给我鼓掌，音乐响起来！ 合理程度:1.76819201152666e-65\n",
      "句子:大家晚上好，我是995号练习生，我是老六我会唱，请大家给我支持，音乐响起来！ 合理程度:2.769153820939576e-53\n",
      "句子:现场粉丝们大家晚上好，我是6号练习生，我是张三我会唱唱，请大家给我投票，音乐响起来！ 合理程度:5.709136738823946e-61\n",
      "句子:大家早上好，我是13号练习生，我是老六的妹妹铁柱我会rap，请大家给我支持，音乐响起来！ 合理程度:1.5274465538329091e-53\n",
      "句子:大家早上好，我是59号练习生，我是李四我会跳跳跳跳rap篮球，请大家给我鼓掌，音乐响起来！ 合理程度:9.633538039649298e-49\n",
      "句子:大家晚上好，我是2272923号练习生，我是张三我会跳，希望大家给我投票，音乐响起来！ 合理程度:6.523457272337893e-54\n",
      "\n",
      "共生成20个句子，其中最合理的句子及其合理程度为：['大家早上好，我是755号练习生，我是李四我会篮球，希望大家给我鼓掌，音乐响起来！', 2.32689960997987e-44]\n"
     ]
    }
   ],
   "source": [
    "generate_best(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- 问题1：\n",
    "  - 数据集与待检测的句子不是很匹配。采用的数据集是豆瓣的影评数据，而按照语法规则生成的句子主要是练习生介绍，两者从内容属性角度来看就存在着很大的差异。\n",
    "- 问题2：\n",
    "  - 生成句子的语法规则内容不够正式，导致每个生成的句子合理程度较低。比如：我是王五的妹妹狗蛋，按照分词处理的话“妹妹”和“狗蛋”会合成一个新词，但是这个新词在整个豆瓣的影评数据集中出现的概率是相当低的。\n",
    "- 问题3：\n",
    "  - 采用了2-gram语言模型，只考虑了句子中连续的2个单词之间的相互的影响。但是一个句子中的单词其实都会互相产生影响，只不过是影响的强弱不同。当前模型没有考虑或者说弱化了一个句子中距离较远的单词之间的相互影响。\n",
    "- 问题4：\n",
    "  - 在对清洗后的数据进行分词处理前，把数据先存到了文本里然后再逐行读取进行分词处理，这样在处理位于一行中的末尾和下一行的开头的单词时分词结果就有可能会产生误差，一旦数据量足够大文本行数足够多，分词所产生的误差就会对最终的判断结果产生一定的影响。\n",
    "- 问题5：\n",
    "  - 整个模型使用了多个函数，调用较为麻烦，灵活度不够\n",
    "- 如何提升\n",
    "  - 调整生成句子的语法规则，使得句子更加具有普适性，能够适应不同类型的数据集\n",
    "  - 学习使用3-gram语法模型提升概率精度\n",
    "  - 后期提升电脑配置，从而改变一行一行处理数据的方式，提高分词准确性\n",
    "  - 将这个模型整理成一个类，通过调用不同的方法来实现灵活的切换生成句子的语法规则、数据集、生成句子数量、语言模型等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
